{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doctor Type ML Automation\n",
    "Amy Jin\n",
    "\n",
    "July 10th, 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from pandas.plotting import scatter_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "#Import Random Forest Model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import tree\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import metrics\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.externals.six import StringIO  \n",
    "from IPython.display import Image  \n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.decomposition import RandomizedPCA\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from collections import Counter\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "# global import\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import operator\n",
    "import time\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "# Connect to Parenthood server\n",
    "import mysql.connector\n",
    "import sshtunnel\n",
    "import pureyaml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetDataFromParenthood(db_name, table_name):\n",
    "    \n",
    "    # handle path\n",
    "    project_dir = !pwd  # dir of current script/notebook file\n",
    "    config_file = open(project_dir[0] + \"/db.yaml\")\n",
    "    config = pureyaml.load(config_file.read())\n",
    "    config_file2 = open(project_dir[0] + \"/db2.yaml\")\n",
    "    config2 = pureyaml.load(config_file2.read())\n",
    "\n",
    "    # argument dictionary for sshtunnel\n",
    "    ssh_config = {\n",
    "        'ssh_address_or_host': ('parenthood.set.care', 22),\n",
    "        'ssh_username':        config['ssh_username'],\n",
    "        'ssh_password':        config['ssh_password'],\n",
    "        'remote_bind_address': ('127.0.0.1', 3306),\n",
    "        'local_bind_address':  ('0.0.0.0', 3333),\n",
    "    }\n",
    "\n",
    "    # argument dictionary for mysql.connector\n",
    "    mysql_config = {\n",
    "        'user':     config['mysql_user'],\n",
    "        'password': config['mysql_passwd'],\n",
    "        'host':     config['mysql_host'],\n",
    "        'database': 'patch',\n",
    "        'port':     3333,\n",
    "    }  \n",
    "    \n",
    "    #table1 = str(db_name) + '.' + str(table_name)\n",
    "    with sshtunnel.SSHTunnelForwarder(**ssh_config) as tunnel:\n",
    "        connection = mysql.connector.connect(**mysql_config)\n",
    "        cur = connection.cursor()\n",
    "        \n",
    "        # Use `DISTINCT` to reduce the calculation load\n",
    "        query = ('''\n",
    "            SELECT *\n",
    "            FROM {db}.{t1} AS A;\n",
    "        '''.format(db = db_name, t1 = table_name))\n",
    "\n",
    "        cur.execute(query)\n",
    "        rows = list(sum(cur.fetchall(), ()))\n",
    "        #print rows, len(rows)\n",
    "        #df = pd.DataFrame(rows)\n",
    "        #print df\n",
    "        #print df.shape\n",
    "        \n",
    "        # Get columans \n",
    "        colnames = ['npi', 'Y_is_oncologist', 'Certification', 'patient_count']\n",
    "        for i in range(1, 11):  # do the following 10 times:\n",
    "            colnames.append('X' + str(i))\n",
    "\n",
    "        # Transform a long list to a (n, 14) dataframe\n",
    "        # -1 simply means that it is an unknown dimension and we want numpy to figure it out.\n",
    "        df_reformat =  pd.DataFrame(np.array(rows).reshape(-1, 14), columns=colnames)\n",
    "        return df_reformat\n",
    "            \n",
    "        cur.close()\n",
    "        connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2738.5135969999997"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tic = time.clock()\n",
    "data = GetDataFromParenthood('ml_provider_type', 'final_table')\n",
    "toc = time.clock()\n",
    "toc - tic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"/Users/yuejin/Documents/AmyJin_2018/Work/Test/2018_03/Doctor_Type_ML/final_table2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>npi</th>\n",
       "      <th>Y_is_oncologist</th>\n",
       "      <th>Certification</th>\n",
       "      <th>patient_count</th>\n",
       "      <th>X_96413</th>\n",
       "      <th>X_96367</th>\n",
       "      <th>X_96361</th>\n",
       "      <th>X_80053</th>\n",
       "      <th>X_G0008</th>\n",
       "      <th>X_83615</th>\n",
       "      <th>X_82728</th>\n",
       "      <th>X_83550</th>\n",
       "      <th>X_J3490</th>\n",
       "      <th>X_Q2037</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1003000134</td>\n",
       "      <td>0</td>\n",
       "      <td>Dermatopathology</td>\n",
       "      <td>4686</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1003000407</td>\n",
       "      <td>0</td>\n",
       "      <td>Family Medicine/OMT</td>\n",
       "      <td>493</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1003000480</td>\n",
       "      <td>0</td>\n",
       "      <td>Surgery</td>\n",
       "      <td>147</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          npi  Y_is_oncologist        Certification  patient_count  X_96413  \\\n",
       "0  1003000134                0     Dermatopathology           4686      0.0   \n",
       "1  1003000407                0  Family Medicine/OMT            493      0.0   \n",
       "2  1003000480                0              Surgery            147      0.0   \n",
       "\n",
       "   X_96367  X_96361  X_80053  X_G0008  X_83615  X_82728  X_83550  X_J3490  \\\n",
       "0      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "1      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "2      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "\n",
       "   X_Q2037  \n",
       "0      0.0  \n",
       "1      0.0  \n",
       "2      0.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "npi                  int64\n",
      "Y_is_oncologist      int64\n",
      "Certification       object\n",
      "patient_count        int64\n",
      "X_96413            float64\n",
      "X_96367            float64\n",
      "X_96361            float64\n",
      "X_80053            float64\n",
      "X_G0008            float64\n",
      "X_83615            float64\n",
      "X_82728            float64\n",
      "X_83550            float64\n",
      "X_J3490            float64\n",
      "X_Q2037            float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Model_Logistic(data):\n",
    "    \n",
    "    train, test = train_test_split(data, test_size=0.2, random_state = 100)\n",
    "    X_train = train.iloc[:,4:14]\n",
    "    y_train = train.iloc[:,1]\n",
    "    X_data = data.iloc[:,4:14]\n",
    "    y_data = data.iloc[:,1]\n",
    "    \n",
    "    ros = RandomOverSampler(random_state=0)\n",
    "    X_resampled, y_resampled = ros.fit_sample(X_train, y_train)\n",
    "    \n",
    "    logisticRegr = LogisticRegression(random_state=0)\n",
    "    X_resampled = pd.DataFrame(X_resampled)\n",
    "    logisticRegr.fit(X_resampled.iloc[:,[0,1,2,4,5,9]], y_resampled)\n",
    "    y_data_pred = logisticRegr.predict(X_data.iloc[:,[0,1,2,4,5,9]])\n",
    "    \n",
    "    confusion_mtx = confusion_matrix(y_data, y_data_pred)\n",
    "    print \"Confusion Matrix for Logistic Regression with 6 features is:\"\n",
    "    print(confusion_mtx)\n",
    "    return y_data_pred\n",
    "    #return confusion_mtx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for Logistic Regression with 6 features is:\n",
      "[[183399   2005]\n",
      " [   380    209]]\n",
      "[u'0' u'0' u'0' ... u'0' u'0' u'0']\n"
     ]
    }
   ],
   "source": [
    "logist_pred = Model_Logistic(data)\n",
    "print logist_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Model_Tree(data):\n",
    "    \n",
    "    train, test = train_test_split(data, test_size=0.2, random_state = 100)\n",
    "    X_train = train.iloc[:,4:14]\n",
    "    y_train = train.iloc[:,1]\n",
    "    X_data = data.iloc[:,4:14]\n",
    "    y_data = data.iloc[:,1]\n",
    "        \n",
    "    ros = RandomOverSampler(random_state=0)\n",
    "    X_resampled, y_resampled = ros.fit_sample(X_train, y_train)\n",
    "    \n",
    "    clf_gini_3 = DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
    "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
    "            presort=False, random_state=None, splitter='best')\n",
    "    clf_gini_3.fit(X_resampled, y_resampled)\n",
    "    y_data_pred = clf_gini_3.predict(X_data)\n",
    "\n",
    "    confusion_mtx = confusion_matrix(y_data, y_data_pred)\n",
    "    print \"Confusion Matrix for Decision Tree with Gini Index is:\"\n",
    "    print(confusion_mtx)\n",
    "    return y_data_pred\n",
    "    #return confusion_mtx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for Decision Tree with Gini Index is:\n",
      "[[185363     41]\n",
      " [   401    188]]\n",
      "[u'0' u'0' u'0' ... u'0' u'0' u'0']\n"
     ]
    }
   ],
   "source": [
    "tree_pred = Model_Tree(data)\n",
    "print tree_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Model_RF(data):\n",
    "    \n",
    "    train, test = train_test_split(data, test_size=0.2, random_state = 100)\n",
    "    X_train = train.iloc[:,4:14]\n",
    "    y_train = train.iloc[:,1]\n",
    "    X_data = data.iloc[:,4:14]\n",
    "    y_data = data.iloc[:,1]\n",
    "\n",
    "    clf_RF = RandomForestClassifier(n_estimators=100)\n",
    "    #Train the model using the training sets y_pred=clf.predict(X_test)\n",
    "    clf_RF.fit(X_train,y_train)\n",
    "\n",
    "    y_data_pred=clf_RF.predict(X_data)\n",
    "\n",
    "    confusion_mtx = confusion_matrix(y_data, y_data_pred)\n",
    "    print \"Confusion Matrix for Random Forest with Gini Index is:\"\n",
    "    print(confusion_mtx)\n",
    "    return y_data_pred\n",
    "    #return confusion_mtx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for Random Forest with Gini Index is:\n",
      "[[185394     10]\n",
      " [   407    182]]\n",
      "[u'0' u'0' u'0' ... u'0' u'0' u'0']\n"
     ]
    }
   ],
   "source": [
    "RF_pred = Model_RF(data)\n",
    "print RF_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Model_NaiveBayes(data):\n",
    "    \n",
    "    train, test = train_test_split(data, test_size=0.2, random_state = 100)\n",
    "    X_train = train.iloc[:,4:14]\n",
    "    y_train = train.iloc[:,1]\n",
    "    X_data = data.iloc[:,4:14]\n",
    "    y_data = data.iloc[:,1]\n",
    "\n",
    "    GNB = GaussianNB()\n",
    "    GNB.fit(X_train, y_train)\n",
    "    y_data_pred = GNB.predict(X_data)\n",
    "    \n",
    "    confusion_mtx = confusion_matrix(y_data, y_data_pred)\n",
    "    print \"Confusion Matrix for Naive Bayes is:\"\n",
    "    print(confusion_mtx)\n",
    "    return y_data_pred\n",
    "    #return confusion_mtx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for Naive Bayes is:\n",
      "[[182477   2927]\n",
      " [   383    206]]\n",
      "[u'0' u'0' u'0' ... u'0' u'0' u'0']\n"
     ]
    }
   ],
   "source": [
    "NB_pred = Model_NaiveBayes(data)\n",
    "print NB_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Model_SVM_sigmoid(data):\n",
    "    \n",
    "    train, test = train_test_split(data, test_size=0.2, random_state = 100)\n",
    "    X_train = train.iloc[:,4:14]\n",
    "    y_train = train.iloc[:,1]\n",
    "    X_data = data.iloc[:,4:14]\n",
    "    y_data = data.iloc[:,1]\n",
    "    \n",
    "    pca = PCA(n_components=2)\n",
    "    pca.fit(X_train)\n",
    "    X_pca = pca.transform(X_train)\n",
    "    train_2d = pca.transform(X_train)\n",
    "    data_2d = pca.transform(X_data)\n",
    "    \n",
    "    pca = RandomizedPCA(n_components=150, whiten=True, random_state=42)\n",
    "    sigmoid_SVM = SVC(kernel='sigmoid')\n",
    "    sigmoid_SVM.fit(train_2d, y_train)\n",
    "    y_data_pred = sigmoid_SVM.predict(data_2d)\n",
    "    \n",
    "    confusion_mtx = confusion_matrix(y_data, y_data_pred)\n",
    "    print \"Confusion Matrix for SVM with sigmoid kernel is:\"\n",
    "    print(confusion_mtx)\n",
    "    return y_data_pred\n",
    "    #return confusion_mtx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for SVM with sigmoid kernel is:\n",
      "[[185404      0]\n",
      " [   589      0]]\n",
      "[u'0' u'0' u'0' ... u'0' u'0' u'0']\n"
     ]
    }
   ],
   "source": [
    "SVM_sigmoid_pred = Model_SVM_sigmoid(data)\n",
    "print SVM_sigmoid_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Model_SVM_linear(data, C):\n",
    "    \n",
    "    train, test = train_test_split(data, test_size=0.2, random_state = 100)\n",
    "    X_train = train.iloc[:,4:14]\n",
    "    y_train = train.iloc[:,1]\n",
    "    X_data = data.iloc[:,4:14]\n",
    "    y_data = data.iloc[:,1]\n",
    "    \n",
    "    pca = PCA(n_components=2)\n",
    "    pca.fit(X_train)\n",
    "    X_pca = pca.transform(X_train)\n",
    "    train_2d = pca.transform(X_train)\n",
    "    data_2d = pca.transform(X_data)\n",
    "    \n",
    "    pca = RandomizedPCA(n_components=150, whiten=True, random_state=42)\n",
    "    linear_SVM = SVC(kernel='linear', class_weight='balanced', C = 1)\n",
    "    linear_SVM.fit(train_2d, y_train)\n",
    "    y_data_pred = linear_SVM.predict(data_2d)\n",
    "\n",
    "\n",
    "    confusion_mtx = confusion_matrix(y_data, y_data_pred)\n",
    "    print \"Confusion Matrix for SVM with linear kernel is:\"\n",
    "    print(confusion_mtx)\n",
    "    return y_data_pred\n",
    "    #return confusion_mtx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for SVM with linear kernel is:\n",
      "[[180569   4835]\n",
      " [   481    108]]\n",
      "[u'0' u'0' u'0' ... u'0' u'0' u'0']\n"
     ]
    }
   ],
   "source": [
    "SVM_linear_pred = Model_SVM_linear(data, 1)\n",
    "print SVM_linear_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Model_kNN_linear(data, n_neighbors):\n",
    "    \n",
    "    train, test = train_test_split(data, test_size=0.2, random_state = 100)\n",
    "    X_train = train.iloc[:,4:14]\n",
    "    y_train = train.iloc[:,1]\n",
    "    X_data = data.iloc[:,4:14]\n",
    "    y_data = data.iloc[:,1]\n",
    "    \n",
    "    knn = KNeighborsClassifier(n_neighbors=3)\n",
    "    # fitting the model\n",
    "    knn.fit(X_train, y_train)\n",
    "    # predict the response\n",
    "    y_data_pred = knn.predict(X_data)\n",
    "    \n",
    "    confusion_mtx = confusion_matrix(y_data, y_data_pred)\n",
    "    print \"Confusion Matrix for kNN is:\"\n",
    "    print(confusion_mtx)\n",
    "    return y_data_pred\n",
    "    #return confusion_mtx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for kNN is:\n",
      "[[185373     31]\n",
      " [   532     57]]\n",
      "[u'0' u'0' u'0' ... u'0' u'0' u'0']\n"
     ]
    }
   ],
   "source": [
    "kNN_pred = Model_kNN_linear(data, 10)\n",
    "print kNN_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Model_LDA_linear(data):\n",
    "    \n",
    "    train, test = train_test_split(data, test_size=0.2, random_state = 100)\n",
    "    X_train = train.iloc[:,4:14]\n",
    "    y_train = train.iloc[:,1]\n",
    "    X_data = data.iloc[:,4:14]\n",
    "    y_data = data.iloc[:,1]\n",
    "\n",
    "    lda = LinearDiscriminantAnalysis()\n",
    "    model_lda = lda.fit(X_train, y_train)\n",
    "    y_data_pred=model_lda.predict(X_data)\n",
    "\n",
    "    confusion_mtx = confusion_matrix(y_data, y_data_pred)\n",
    "    print \"Confusion Matrix for LDA is:\"\n",
    "    print(confusion_mtx)\n",
    "    return y_data_pred\n",
    "    #return confusion_mtx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for LDA is:\n",
      "[[184042   1362]\n",
      " [   395    194]]\n",
      "[u'0' u'0' u'0' ... u'0' u'0' u'0']\n"
     ]
    }
   ],
   "source": [
    "LDA_pred = Model_LDA_linear(data)\n",
    "print LDA_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Model_QDA_linear(data):\n",
    "    \n",
    "    train, test = train_test_split(data, test_size=0.2, random_state = 100)\n",
    "    X_train = train.iloc[:,4:14]\n",
    "    y_train = train.iloc[:,1]\n",
    "    X_data = data.iloc[:,4:14]\n",
    "    y_data = data.iloc[:,1]\n",
    "    \n",
    "    qda = QuadraticDiscriminantAnalysis()\n",
    "    model_qda = qda.fit(X_train, y_train)\n",
    "    y_data_pred=model_qda.predict(X_data)\n",
    "\n",
    "    confusion_mtx = confusion_matrix(y_data, y_data_pred)\n",
    "    print \"Confusion Matrix for QDA is:\"\n",
    "    print(confusion_mtx)\n",
    "    return y_data_pred\n",
    "    #return confusion_mtx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for QDA is:\n",
      "[[182389   3015]\n",
      " [   379    210]]\n",
      "[u'0' u'0' u'0' ... u'0' u'0' u'0']\n"
     ]
    }
   ],
   "source": [
    "QDA_pred = Model_QDA_linear(data)\n",
    "print QDA_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Model_GBM_linear(data, n_estimators=100, learning_rate=1.0, max_depth=1, random_state=0):\n",
    "    \n",
    "    train, test = train_test_split(data, test_size=0.2, random_state = 100)\n",
    "    X_train = train.iloc[:,4:14]\n",
    "    y_train = train.iloc[:,1]\n",
    "    X_data = data.iloc[:,4:14]\n",
    "    y_data = data.iloc[:,1]\n",
    "    \n",
    "    model_BGM= GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=0)\n",
    "    # Train the model using the training sets and check score\n",
    "    model_BGM.fit(X_train, y_train)\n",
    "    y_data_pred = model_BGM.predict(X_data)\n",
    "    \n",
    "    confusion_mtx = confusion_matrix(y_data, y_data_pred)\n",
    "    print \"Confusion Matrix for GBM is:\"\n",
    "    print(confusion_mtx)\n",
    "    return y_data_pred\n",
    "    #return confusion_mtx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for GBM is:\n",
      "[[184253   1151]\n",
      " [   399    190]]\n",
      "[u'0' u'0' u'0' ... u'0' u'0' u'0']\n"
     ]
    }
   ],
   "source": [
    "GBM_pred = Model_GBM_linear(data)\n",
    "print GBM_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Model_XGBoost_linear(data):\n",
    "    \n",
    "    train, test = train_test_split(data, test_size=0.2, random_state = 100)\n",
    "    X_train = train.iloc[:,4:14]\n",
    "    y_train = train.iloc[:,1]\n",
    "    X_data = data.iloc[:,4:14]\n",
    "    y_data = data.iloc[:,1]\n",
    "    #print X_train.dtypes\n",
    "    \n",
    "    model_XGB = XGBClassifier()\n",
    "    model_XGB.fit(X_train, y_train)\n",
    "    y_data_pred = model_XGB.predict(X_data)\n",
    "    \n",
    "    confusion_mtx = confusion_matrix(y_data, y_data_pred)\n",
    "    print \"Confusion Matrix for XGBoost is:\"\n",
    "    print(confusion_mtx)\n",
    "    return y_data_pred\n",
    "    #return confusion_mtx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for XGBoost is:\n",
      "[[185397      7]\n",
      " [   573     16]]\n",
      "[0 0 0 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "XGBoost_pred = Model_XGBoost_linear(data)\n",
    "print XGBoost_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def UploadPredictionsToParenthood(db_name, db_table_name, table_to_upload):\n",
    "\n",
    "    # handle path\n",
    "    project_dir = !pwd  # dir of current script/notebook file\n",
    "    config_file = open(project_dir[0] + \"/db.yaml\")\n",
    "    config = pureyaml.load(config_file.read())\n",
    "    config_file2 = open(project_dir[0] + \"/db2.yaml\")\n",
    "    config2 = pureyaml.load(config_file2.read())\n",
    "\n",
    "    # argument dictionary for sshtunnel\n",
    "    ssh_config = {\n",
    "        'ssh_address_or_host': ('parenthood.set.care', 22),\n",
    "        'ssh_username':        config['ssh_username'],\n",
    "        'ssh_password':        config['ssh_password'],\n",
    "        'remote_bind_address': ('127.0.0.1', 3306),\n",
    "        'local_bind_address':  ('0.0.0.0', 3333),\n",
    "    }\n",
    "\n",
    "    # argument dictionary for mysql.connector\n",
    "    mysql_config = {\n",
    "        'user':     config['mysql_user'],\n",
    "        'password': config['mysql_passwd'],\n",
    "        'host':     config['mysql_host'],\n",
    "        'database': 'patch',\n",
    "        'port':     3333,\n",
    "    }       \n",
    "    #table1 = str(db_name) + '.' + str(table_name)\n",
    "    with sshtunnel.SSHTunnelForwarder(**ssh_config) as tunnel:\n",
    "\n",
    "        connection = mysql.connector.connect(**mysql_config)\n",
    "        cur = connection.cursor()\n",
    "        \n",
    "        # Import dataframe into MySQL\n",
    "        import sqlalchemy\n",
    "        database_username = config2['database_username']\n",
    "        database_password = config2['database_password']\n",
    "        database_ip       = config2['database_ip']\n",
    "        database_name     = db_name\n",
    "    \n",
    "        database_connection = sqlalchemy.create_engine('mysql+pymysql://{0}:{1}@{2}/{3}'.\n",
    "                                                       format(database_username, database_password, \n",
    "                                                              database_ip, database_name))\n",
    "        table_to_upload.to_sql(con=database_connection, name= db_table_name, if_exists='replace')\n",
    "        print \"Table has been uploaded successfully!\"\n",
    "            \n",
    "        cur.close()\n",
    "        connection.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table has been uploaded successfully!\n"
     ]
    }
   ],
   "source": [
    "UploadPredictionsToParenthood('ml_provider_type','test_table_2', test_df_2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
